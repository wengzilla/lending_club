{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pdb \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import util\n",
    "import seaborn as sns \n",
    "import clean_data as cd\n",
    "import benchmark\n",
    "import group_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/IPython/core/interactiveshell.py:3006: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "pd2007 = cd.import_data(2007)\n",
    "pd2012 = cd.import_data(2012)\n",
    "\n",
    "all_data = pd.concat([pd2007, pd2012])\n",
    "prepped_data = cd.prep_for_classification(all_data)\n",
    "X, y = cd.feature_target_split(prepped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark for all data on A/B/C: 1.08\n",
      "Benchmar for all data on all loans: 1.08\n",
      "Benchmark for all data is : 1.08\n",
      "Benchmark for 2012 data is: 1.09\n",
      "Benchmark for 2007 data is: 1.08\n",
      "Making group for group A\n",
      "Making group for group B\n",
      "Making group for group C\n",
      "Making group for group D\n",
      "Making group for group E\n",
      "Making group for group F\n",
      "Making group for group G\n",
      "Precision for group A: 0.90\n",
      "Benchmark for group A: 1.09\n",
      "[[ 349   32]\n",
      " [  40 5995]]\n",
      "Precision for group B: 0.77\n",
      "Benchmark for group B: 1.16\n",
      "[[1251  114]\n",
      " [ 376 9304]]\n",
      "Precision for group C: 0.18\n",
      "Benchmark for group C: 1.03\n",
      "[[1212    5]\n",
      " [5598   13]]\n",
      "Precision for group D: 0.23\n",
      "Benchmark for group D: 1.15\n",
      "[[ 848    0]\n",
      " [2855    1]]\n",
      "Precision for group E: 0.24\n",
      "Benchmark for group E: 0.58\n",
      "[[187   2]\n",
      " [582   3]]\n",
      "Precision for group F: 0.34\n",
      "Benchmark for group F: nan\n",
      "[[41  0]\n",
      " [79  0]]\n",
      "Precision for group G: 0.27\n",
      "Benchmark for group G: nan\n",
      "[[ 4  0]\n",
      " [11  0]]\n",
      "Overall precision: 3892 9541\n",
      "Overall benchmark: 1.13\n"
     ]
    }
   ],
   "source": [
    "# grades are still here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "train_payouts = all_data.ix[X_train.index]['payout_prop']\n",
    "test_payouts = all_data.ix[X_test.index]['payout_prop']\n",
    "\n",
    "print \"Benchmark for all data on A/B/C: %.2f\" %benchmark.total_return(all_data, filter_col='grade', filter_vals=['A', 'B', 'C'])\n",
    "print \"Benchmar for all data on all loans: %.2f\" %benchmark.total_return(all_data)\n",
    "print \"Benchmark for all data is : %.2f\" %np.mean(all_data['payout_prop'])\n",
    "print \"Benchmark for 2012 data is: %.2f\" %np.mean(pd2012['payout_prop'])\n",
    "print \"Benchmark for 2007 data is: %.2f\" %np.mean(pd2007['payout_prop'])\n",
    "\n",
    "lr_params = { \n",
    "    'C': 100,\n",
    "    'class_weight': {False: 15},\n",
    "    'penalty': 'l2',\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "models = group_models.fit(X_train, y_train, 'grade', LogisticRegression, lr_params)\n",
    "group_models.group_results(X_test, y_test, test_payouts, 'grade', models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight={False: 15}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lr_model = LogisticRegression(**lr_params)\n",
    "all_lr_model.fit(X_train.drop('grade', axis=1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = all_lr_model.predict(X_test.drop('grade', axis=1))\n",
    "cm_all_model = confusion_matrix(y_test, predicted, labels=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.987076417704\n"
     ]
    }
   ],
   "source": [
    "precision_all = cm_all_model[0,0] / np.sum(cm_all_model[:, 0])\n",
    "print precision_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1659078177304181"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_indices = [X_test.index[i] for i in range(len(X_test)) if predicted[i] == 1]\n",
    "predicted_df = all_data.ix[all_model_indices]\n",
    "benchmark.total_return(predicted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22837  2020]\n",
      " [  299  3746]]\n"
     ]
    }
   ],
   "source": [
    "print cm_all_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Total pred 1: ', 6011)\n",
      "Group A\n",
      "[[5965   70]\n",
      " [  46  335]]\n",
      "Precision: 0.99\n",
      "=======================================================\n",
      "(' Total pred 1: ', 9438)\n",
      "Group B\n",
      "[[9312  368]\n",
      " [ 126 1239]]\n",
      "Precision: 0.99\n",
      "=======================================================\n",
      "(' Total pred 1: ', 4980)\n",
      "Group C\n",
      "[[4902  709]\n",
      " [  78 1139]]\n",
      "Precision: 0.98\n",
      "=======================================================\n",
      "(' Total pred 1: ', 2249)\n",
      "Group D\n",
      "[[2210  646]\n",
      " [  39  809]]\n",
      "Precision: 0.98\n",
      "=======================================================\n",
      "(' Total pred 1: ', 399)\n",
      "Group E\n",
      "[[391 194]\n",
      " [  8 181]]\n",
      "Precision: 0.98\n",
      "=======================================================\n",
      "(' Total pred 1: ', 52)\n",
      "Group F\n",
      "[[50 29]\n",
      " [ 2 39]]\n",
      "Precision: 0.96\n",
      "=======================================================\n",
      "(' Total pred 1: ', 7)\n",
      "Group G\n",
      "[[7 4]\n",
      " [0 4]]\n",
      "Precision: 1.00\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "test_copy = X_test.copy()\n",
    "test_copy['prediction'] = predicted\n",
    "grouped_test = test_copy.groupby('grade')\n",
    "\n",
    "for gname, df in grouped_test:\n",
    "    y_group = y_test.ix[df.index]\n",
    "    print (\" Total pred 1: \", np.sum(df['prediction']))\n",
    "    cm_group = confusion_matrix(y_group, df['prediction'], labels=[True, False])\n",
    "    print \"Group %s\" %gname\n",
    "    print cm_group\n",
    "    print \"Precision: %.2f\" %(float(cm_group[0, 0]) / float(cm_group[0,0] + cm_group[1, 0]))\n",
    "    print(\"=======================================================\")\n",
    "    # grab rows by grade\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
